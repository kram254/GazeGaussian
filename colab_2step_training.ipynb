{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GazeGaussian Enhanced (DiT) - 2-Step Training\n",
    "\n",
    "## Overview\n",
    "This notebook trains the enhanced GazeGaussian model with:\n",
    "1. **DiT Neural Renderer** (replacing U-Net)\n",
    "2. **VAE Integration**\n",
    "3. **Orthogonality Regularization**\n",
    "\n",
    "## Training Process\n",
    "- **Step 1**: Train MeshHead (~10 epochs, ~2-3 hours)\n",
    "- **Step 2**: Train GazeGaussian with DiT (~30 epochs, ~8-12 hours)\n",
    "\n",
    "## Requirements\n",
    "- GPU: A100 (40GB recommended) or V100 (32GB minimum)\n",
    "- Dataset: ETH-XGaze training set in Google Drive\n",
    "- Time: ~12-15 hours total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!rm -rf GazeGaussian\n",
    "!git clone --recursive https://github.com/kram254/GazeGaussian.git\n",
    "%cd GazeGaussian\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A. ALTERNATIVE: Install Optuna for Automated Training (Optional)\n",
    "\n",
    "If you want to use automated hyperparameter optimization instead of manual training, install Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna optuna-dashboard plotly kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools wheel ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python h5py tqdm scipy scikit-image lpips kornia tensorboardX einops trimesh plyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build CUDA Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian/submodules/diff-gaussian-rasterization\n",
    "!python setup.py install\n",
    "%cd /content/GazeGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian/submodules/simple-knn\n",
    "!python setup.py install\n",
    "%cd /content/GazeGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaolin-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_good = True\n",
    "\n",
    "packages = [\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('cv2', 'OpenCV'),\n",
    "    ('h5py', 'h5py'),\n",
    "    ('lpips', 'LPIPS'),\n",
    "    ('kornia', 'Kornia'),\n",
    "]\n",
    "\n",
    "for mod, name in packages:\n",
    "    try:\n",
    "        m = __import__(mod)\n",
    "        v = getattr(m, '__version__', 'OK')\n",
    "        print(f\"✓ {name:15s} {v}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ {name:15s} FAILED: {str(e)[:50]}\")\n",
    "        all_good = False\n",
    "\n",
    "try:\n",
    "    import simple_knn\n",
    "    print(f\"✓ {'simple-knn':15s} OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ {'simple-knn':15s} FAILED: {str(e)[:50]}\")\n",
    "    all_good = False\n",
    "\n",
    "try:\n",
    "    import diff_gaussian_rasterization\n",
    "    print(f\"✓ {'diff-gauss':15s} OK\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ {'diff-gauss':15s} FAILED: {str(e)[:50]}\")\n",
    "    all_good = False\n",
    "\n",
    "try:\n",
    "    import kaolin\n",
    "    try:\n",
    "        kaolin_version = kaolin.__version__\n",
    "    except AttributeError:\n",
    "        kaolin_version = 'OK (version unknown)'\n",
    "    print(f\"✓ {'kaolin':15s} {kaolin_version}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ {'kaolin':15s} FAILED: {str(e)[:50]}\")\n",
    "    all_good = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\n✅ ALL REQUIRED PACKAGES INSTALLED SUCCESSFULLY!\")\n",
    "    print(\"   Ready for training!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some packages failed. Check errors above and rerun failed installations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "from configs.gazegaussian_options import BaseOptions\n",
    "from models.gaze_gaussian import GazeGaussianNet\n",
    "from dataloader.eth_xgaze import get_val_loader\n",
    "\n",
    "def save_image_grid(images, save_path, nrow=4):\n",
    "    grid = vutils.make_grid(images, nrow=nrow, normalize=True, value_range=(-1, 1))\n",
    "    grid_np = grid.cpu().numpy().transpose(1, 2, 0)\n",
    "    grid_np = np.clip((grid_np * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(grid_np).save(save_path)\n",
    "    return grid_np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING TEST SAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "checkpoint_path = \"/content/drive/MyDrive/gazegaussian_dit_final.pth\"\n",
    "data_dir = \"/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/test\"\n",
    "output_dir = \"/content/test_outputs\"\n",
    "num_samples = 10\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n[1/4] Loading checkpoint: {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cuda')\n",
    "print(f\"✓ Checkpoint loaded\")\n",
    "\n",
    "print(f\"\\n[2/4] Initializing model with DiT...\")\n",
    "opt = BaseOptions()\n",
    "\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "elif isinstance(checkpoint, dict):\n",
    "    state_dict = checkpoint\n",
    "else:\n",
    "    state_dict = None\n",
    "\n",
    "model = GazeGaussianNet(opt, load_state_dict=state_dict)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "print(f\"✓ Model initialized\")\n",
    "print(f\"  Neural Renderer: {type(model.neural_render).__name__}\")\n",
    "\n",
    "print(f\"\\n[3/4] Loading test data...\")\n",
    "opt.img_dir = data_dir\n",
    "val_loader = get_val_loader(opt, data_dir=data_dir, batch_size=1, num_workers=0, evaluate=None, dataset_name='eth_xgaze')\n",
    "print(f\"✓ Test data loaded ({len(val_loader.dataset)} samples)\")\n",
    "\n",
    "print(f\"\\n[4/4] Generating {num_samples} samples...\")\n",
    "\n",
    "success = 0\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(tqdm(val_loader, total=num_samples)):\n",
    "        if idx >= num_samples:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            for key in data:\n",
    "                if isinstance(data[key], torch.Tensor):\n",
    "                    data[key] = data[key].cuda()\n",
    "                elif isinstance(data[key], dict):\n",
    "                    for sub_key in data[key]:\n",
    "                        if isinstance(data[key][sub_key], torch.Tensor):\n",
    "                            data[key][sub_key] = data[key][sub_key].cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            gt_image = data.get('image', data.get('img', None))\n",
    "            gaussian_img = output['total_render_dict']['merge_img']\n",
    "            neural_img = output['total_render_dict']['merge_img_pro']\n",
    "            \n",
    "            if gt_image is not None:\n",
    "                comparison = torch.cat([gt_image, gaussian_img, neural_img], dim=0)\n",
    "                labels = \"GT | Gaussian | DiT Enhanced\"\n",
    "            else:\n",
    "                comparison = torch.cat([gaussian_img, neural_img], dim=0)\n",
    "                labels = \"Gaussian | DiT Enhanced\"\n",
    "            \n",
    "            save_path = os.path.join(output_dir, f\"test_sample_{idx:03d}.png\")\n",
    "            save_image_grid(comparison, save_path, nrow=len(comparison))\n",
    "            \n",
    "            save_image_grid(neural_img, os.path.join(output_dir, f\"test_sample_{idx:03d}_dit.png\"), nrow=1)\n",
    "            \n",
    "            success += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error on sample {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✅ Successfully generated {success}/{num_samples} test samples\")\n",
    "print(f\"   Output directory: {output_dir}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "!cp -r {output_dir} /content/drive/MyDrive/gazegaussian_test_outputs\n",
    "print(f\"\\n✓ Copied outputs to Drive: /content/drive/MyDrive/gazegaussian_test_outputs\")\n",
    "\n",
    "print(f\"\\nDisplaying first 5 samples:\")\n",
    "for i in range(min(5, success)):\n",
    "    img_path = os.path.join(output_dir, f\"test_sample_{i:03d}.png\")\n",
    "    if os.path.exists(img_path):\n",
    "        print(f\"\\nSample {i}:\")\n",
    "        display(IPImage(filename=img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/train\")\n",
    "h5_files = sorted([f.name for f in data_dir.glob(\"*.h5\")])\n",
    "\n",
    "print(f\"Found {len(h5_files)} training files\")\n",
    "print(f\"First 5 files: {h5_files[:5]}\")\n",
    "\n",
    "if not h5_files:\n",
    "    print(\"\\n❌ No .h5 files found! Check your path.\")\n",
    "else:\n",
    "    train_split = int(len(h5_files) * 0.9)\n",
    "    train_files = h5_files[:train_split]\n",
    "    val_files = h5_files[train_split:]\n",
    "\n",
    "    custom_config = {\n",
    "        \"train\": train_files,\n",
    "        \"val\": val_files,\n",
    "        \"val_gaze\": val_files,\n",
    "        \"test\": [],\n",
    "        \"test_specific\": []\n",
    "    }\n",
    "\n",
    "    config_path = \"/content/GazeGaussian/configs/dataset/eth_xgaze/train_test_split.json\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(custom_config, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✓ Updated config\")\n",
    "    print(f\"  - Training files: {len(train_files)}\")\n",
    "    print(f\"  - Validation files: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. STEP 1: Train MeshHead (~10 epochs, ~2-3 hours)\n",
    "\n",
    "This creates the canonical 3D head model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6A. ALTERNATIVE: Train MeshHead with Optuna Optimization\n",
    "\n",
    "This will automatically search for the best hyperparameters (learning rate, MLP sizes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian\n",
    "\n",
    "!python train_meshhead_optuna.py \\\n",
    "    --batch_size 1 \\\n",
    "    --name 'meshhead' \\\n",
    "    --img_dir '/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/train' \\\n",
    "    --num_epochs 10 \\\n",
    "    --num_workers 2 \\\n",
    "    --early_stopping \\\n",
    "    --patience 5 \\\n",
    "    --dataset_name 'eth_xgaze' \\\n",
    "    --n_trials 15 \\\n",
    "    --study_name 'meshhead_optuna' \\\n",
    "    --optuna_storage 'sqlite:///meshhead_optuna.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian\n",
    "\n",
    "!python train_meshhead.py \\\n",
    "    --batch_size 1 \\\n",
    "    --name 'meshhead' \\\n",
    "    --img_dir '/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/train' \\\n",
    "    --num_epochs 10 \\\n",
    "    --num_workers 2 \\\n",
    "    --early_stopping \\\n",
    "    --patience 5 \\\n",
    "    --dataset_name 'eth_xgaze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify MeshHead Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoints = glob.glob(\"/content/GazeGaussian/work_dirs/meshhead_*/checkpoints/*.pth\")\n",
    "if checkpoints:\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    print(f\"✓ MeshHead checkpoint found: {latest_checkpoint}\")\n",
    "    print(f\"  Size: {os.path.getsize(latest_checkpoint) / (1024**2):.2f} MB\")\n",
    "    \n",
    "    with open('/content/meshhead_checkpoint.txt', 'w') as f:\n",
    "        f.write(latest_checkpoint)\n",
    "    print(f\"\\n✓ Checkpoint path saved for Step 2\")\n",
    "else:\n",
    "    print(\"❌ No MeshHead checkpoint found! Training may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify DiT Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.gazegaussian_options import BaseOptions\n",
    "\n",
    "opt = BaseOptions()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENHANCED MODEL CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Neural Renderer Type: {opt.neural_renderer_type}\")\n",
    "print(f\"✓ DiT Depth: {opt.dit_depth}\")\n",
    "print(f\"✓ DiT Num Heads: {opt.dit_num_heads}\")\n",
    "print(f\"✓ DiT Patch Size: {opt.dit_patch_size}\")\n",
    "print(f\"✓ VAE Enabled: {opt.use_vae}\")\n",
    "print(f\"✓ VAE Z Channels: {opt.vae_z_channels}\")\n",
    "print(f\"✓ VAE Frozen: {opt.freeze_vae}\")\n",
    "print(f\"✓ Orthogonality Loss: {opt.use_orthogonality_loss}\")\n",
    "print(f\"✓ Orthogonality Importance: {opt.orthogonality_loss_importance}\")\n",
    "\n",
    "if opt.neural_renderer_type == \"dit\" and opt.use_vae and opt.use_orthogonality_loss:\n",
    "    print(\"\\n✅ All 3 enhancements are ACTIVE!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some enhancements may be disabled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. STEP 2: Train GazeGaussian with DiT (~30 epochs, ~8-12 hours)\n",
    "\n",
    "This trains the full pipeline with your 3 enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian\n",
    "\n",
    "with open('/content/meshhead_checkpoint.txt', 'r') as f:\n",
    "    meshhead_checkpoint = f.read().strip()\n",
    "\n",
    "print(f\"Loading MeshHead from: {meshhead_checkpoint}\")\n",
    "\n",
    "!python train_gazegaussian.py \\\n",
    "    --batch_size 1 \\\n",
    "    --name 'gazegaussian_dit' \\\n",
    "    --img_dir '/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/train' \\\n",
    "    --num_epochs 30 \\\n",
    "    --num_workers 2 \\\n",
    "    --lr 0.0001 \\\n",
    "    --clip_grad \\\n",
    "    --load_meshhead_checkpoint {meshhead_checkpoint} \\\n",
    "    --dataset_name 'eth_xgaze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9A. ALTERNATIVE: Train GazeGaussian with Optuna Optimization\n",
    "\n",
    "This will automatically search for the best hyperparameters (learning rate, DiT depth/heads/patch size, loss weights, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/GazeGaussian\n",
    "\n",
    "with open('/content/meshhead_checkpoint.txt', 'r') as f:\n",
    "    meshhead_checkpoint = f.read().strip()\n",
    "\n",
    "print(f\"Loading MeshHead from: {meshhead_checkpoint}\")\n",
    "\n",
    "!python train_gazegaussian_optuna.py \\\n",
    "    --batch_size 1 \\\n",
    "    --name 'gazegaussian_dit' \\\n",
    "    --img_dir '/content/drive/MyDrive/GazeGaussian_data/ETH-XGaze/train' \\\n",
    "    --num_epochs 30 \\\n",
    "    --num_workers 2 \\\n",
    "    --clip_grad \\\n",
    "    --load_meshhead_checkpoint {meshhead_checkpoint} \\\n",
    "    --dataset_name 'eth_xgaze' \\\n",
    "    --n_trials 20 \\\n",
    "    --study_name 'gazegaussian_optuna' \\\n",
    "    --optuna_storage 'sqlite:///gazegaussian_optuna.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify Final Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoints = glob.glob(\"/content/GazeGaussian/work_dirs/gazegaussian_dit_*/checkpoints/*.pth\")\n",
    "if checkpoints:\n",
    "    latest_checkpoint = sorted(checkpoints)[-1]\n",
    "    print(f\"✓ GazeGaussian checkpoint found: {latest_checkpoint}\")\n",
    "    print(f\"  Size: {os.path.getsize(latest_checkpoint) / (1024**2):.2f} MB\")\n",
    "    print(f\"\\n✓ Training complete!\")\n",
    "    print(f\"\\nCopy checkpoint to Drive:\")\n",
    "    !cp {latest_checkpoint} /content/drive/MyDrive/gazegaussian_dit_final.pth\n",
    "    print(\"✓ Saved to Drive: gazegaussian_dit_final.pth\")\n",
    "else:\n",
    "    print(\"❌ No GazeGaussian checkpoint found! Training may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Analyze Optuna Results (If Using Optuna)\n",
    "\n",
    "View optimization history, parameter importance, and best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "\n",
    "study_path = 'sqlite:///gazegaussian_optuna.db'\n",
    "study_name = 'gazegaussian_optuna'\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=study_path)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"OPTUNA OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal trials: {len(study.trials)}\")\n",
    "    print(f\"Best trial: {study.best_trial.number}\")\n",
    "    print(f\"Best validation loss: {study.best_trial.value:.6f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"BEST HYPERPARAMETERS:\")\n",
    "    print(\"=\"*80)\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"  {key:35s}: {value}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"VISUALIZATIONS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n1. Optimization History\")\n",
    "    fig = vis.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n2. Parameter Importances\")\n",
    "    fig = vis.plot_param_importances(study)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n3. Parallel Coordinate Plot\")\n",
    "    fig = vis.plot_parallel_coordinate(study)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n4. Slice Plot\")\n",
    "    fig = vis.plot_slice(study)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n5. Contour Plot (Learning Rate vs DiT Depth)\")\n",
    "    fig = vis.plot_contour(study, params=['lr', 'dit_depth'])\n",
    "    fig.show()\n",
    "    \n",
    "    with open('/content/best_hyperparameters.json', 'w') as f:\n",
    "        json.dump(study.best_trial.params, f, indent=2)\n",
    "    print(f\"\\n✓ Saved best hyperparameters to: /content/best_hyperparameters.json\")\n",
    "    \n",
    "    best_checkpoint = f\"/content/GazeGaussian/work_dirs/gazegaussian_dit_trial_{study.best_trial.number}/checkpoints\"\n",
    "    print(f\"\\n✓ Best checkpoint directory:\")\n",
    "    print(f\"  {best_checkpoint}\")\n",
    "    \n",
    "    !cp -r {best_checkpoint}/*.pth /content/drive/MyDrive/gazegaussian_optuna_best.pth\n",
    "    print(f\"\\n✓ Copied best checkpoint to Google Drive!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading study: {str(e)}\")\n",
    "    print(\"\\nMake sure you ran the Optuna training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Launch Optuna Dashboard (Optional)\n",
    "\n",
    "View interactive dashboard for real-time monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "ngrok.set_auth_token(\"YOUR_NGROK_TOKEN\")\n",
    "\n",
    "port = 8080\n",
    "public_url = ngrok.connect(port)\n",
    "\n",
    "print(f\"=\"*80)\n",
    "print(\"OPTUNA DASHBOARD\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Dashboard URL: {public_url}\")\n",
    "print(f\"\\nOpen this URL in your browser to view the interactive dashboard\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "def run_dashboard():\n",
    "    subprocess.run([\n",
    "        \"optuna-dashboard\",\n",
    "        \"sqlite:///gazegaussian_optuna.db\",\n",
    "        \"--port\", str(port),\n",
    "        \"--host\", \"0.0.0.0\"\n",
    "    ])\n",
    "\n",
    "thread = threading.Thread(target=run_dashboard, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"\\n✓ Dashboard is now running!\")\n",
    "print(\"⚠️  Keep this cell running to maintain the dashboard connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Test Samples\n",
    "\n",
    "Generate a few redirected gaze/pose samples for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add inference code to generate samples\n",
    "# This will be added after confirming training works\n",
    "print(\"Sample generation coming in next update...\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
